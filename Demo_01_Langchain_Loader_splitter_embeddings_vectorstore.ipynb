{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "IY1MDblAlyIG",
   "metadata": {
    "id": "IY1MDblAlyIG"
   },
   "source": [
    "# **Demo: LangChain Loader, Splitter, Embeddings, and VectorStore**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kGVt_ry_Mwyj",
   "metadata": {
    "id": "kGVt_ry_Mwyj"
   },
   "source": [
    "# __Description:__\n",
    "In this activity, you will implement the functionalities of LangChain’s loaders, splitters, embeddings, and VectorStores.\n",
    "The two files in the tutorial serve as practical examples of real-world data that one might encounter in natural language processing tasks. They are:\n",
    "\n",
    "•\tThe **state_of_union.txt** file, which contains transcripts of the United States’ State of the Union Addresses, represents a large text document that can be loaded and processed.\n",
    "\n",
    "•\tThe **michael_resume.pdf** file, an open source resume, represents a common type of document that one might analyze for tasks such as resume screening or information extraction.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TIxRkrn-l5qc",
   "metadata": {
    "id": "TIxRkrn-l5qc"
   },
   "source": [
    "# **Steps to Perform:**\n",
    "\n",
    "\n",
    "1.   Import the Necessary Modules\n",
    "2.   Load Text Data from a File Using TextLoader\n",
    "3.   Load PDFs from the Internet Using PyPDFLoader\n",
    "4.   Split the Documents Using RecursiveCharacterTextSplitter\n",
    "5.   Embed the Documents Using HuggingFaceEmbeddings and Print the Length of the Embedding\n",
    "6.   Embed the Documents Using OpenAIEmbeddings and Print the Length of the Embedding\n",
    "7.   Create a FAISS Instance\n",
    "8.   Perform a Similarity Search on the FAISS Instance\n",
    "9.   Persist the FAISS Instance\n",
    "10.  Load the Persisted FAISS Instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6xcPQbtUNQU6",
   "metadata": {
    "id": "6xcPQbtUNQU6"
   },
   "source": [
    "# **Step 1: Import the Necessary Modules**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6940571-b490-4a34-9586-f8f2de73d967",
   "metadata": {
    "id": "b6940571-b490-4a34-9586-f8f2de73d967",
    "outputId": "2bbf7cd5-625f-49d4-ddc5-416e50694d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pysqlite3 in /voc/work/.local/lib/python3.10/site-packages (0.5.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pysqlite3-binary in /voc/work/.local/lib/python3.10/site-packages (0.5.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/site-packages (3.17.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysqlite3\n",
    "!pip install pysqlite3-binary\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5eb3a8-7af7-4ef6-a610-55b3ea88eb6b",
   "metadata": {
    "id": "fc5eb3a8-7af7-4ef6-a610-55b3ea88eb6b"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import pysqlite3\n",
    "import sys\n",
    "sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YeSU0ZxxNiuM",
   "metadata": {
    "id": "YeSU0ZxxNiuM"
   },
   "source": [
    "#**Step 2: Load Text Data from a File Using TextLoader**\n",
    "\n",
    "\n",
    "\n",
    "*   Print the first 100 characters from the loaded text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ca979f-04fd-4c58-8798-034292d94377",
   "metadata": {
    "id": "a2ca979f-04fd-4c58-8798-034292d94377",
    "outputId": "b13cdbd8-40a8-428b-dd34-3d88d59abf93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and th\n"
     ]
    }
   ],
   "source": [
    "text_loader = TextLoader(\"state_of_union.txt\")\n",
    "text_document = text_loader.load()\n",
    "print(text_document[0].page_content[:100])  # Prints the first 100 characters of the text document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p2SsnXrbNzD5",
   "metadata": {
    "id": "p2SsnXrbNzD5"
   },
   "source": [
    "# **Step 3: Load PDFs from the Internet Using PyPDFLoader**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63ba6b83-4196-4673-829e-d6874bd742a8",
   "metadata": {
    "id": "63ba6b83-4196-4673-829e-d6874bd742a8",
    "outputId": "02ee8210-e2fc-4dd2-af90-a43c7f54acb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRICULUM VITAE :  \n",
      "M ichael M . Scott OBE, B.Sc., Dip.Ed  \n",
      " \n",
      "Home address :  Strome House     Date\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_loader = PyPDFLoader(\"michael_resume.pdf\")\n",
    "pdf_pages = pdf_loader.load_and_split()\n",
    "print(pdf_pages[0].page_content[:100])  # Prints the first 100 characters of the first page of the PDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2IzUICifOBqd",
   "metadata": {
    "id": "2IzUICifOBqd"
   },
   "source": [
    "# **Step 4: Split the Documents Using RecursiveCharacterTextSplitter**\n",
    "\n",
    "\n",
    "*   Split the PDF pages into smaller chunks and print the number of chunks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12653170-35dd-4a70-a997-380006660a23",
   "metadata": {
    "id": "12653170-35dd-4a70-a997-380006660a23",
    "outputId": "74f5cad8-0c2b-415c-fe5e-2d024dcd347a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "split_texts = doc_splitter.split_documents(pdf_pages)\n",
    "print(len(split_texts))  # Prints the number of chunks the PDF has been split into\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rawkX5UeOe8e",
   "metadata": {
    "id": "rawkX5UeOe8e"
   },
   "source": [
    "# **Step 5: Embed the Documents Using HuggingFaceEmbeddings and Print the Length of the Embedding**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e6ffdc-3c5e-468f-9ed7-f703cb9ddad8",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "d64a277a50c74195bc764148604e9a99",
      "4c7c32e3807b43178685892a533c5571",
      "9ec53712abde4c6ab8f6f33aecf4d7bc",
      "50597f9d2d594efda364be18cf17a180",
      "fdcab798b77f45739885570f45132267",
      "151f77060c5a407a9dc523aaf4888221",
      "ddcbbb0397604f5686c8d783a63a29f2",
      "54abd02225434d17bc00568232ada7e0",
      "7f85963918f34167b09fdaf07e907249",
      "d604d2e0d6734b2faaef3e65c8ab06b7",
      "93c4c9fe19e94f1493bc31e66ddaede5",
      "b33005a189c64bb4a430753253ebb9c8",
      "7274d1c1caa64b1f9be31585ecd67430",
      "49d10e1d64004d469bc94847dd1d1037",
      "46f7a294befb41b595619596f168657a"
     ]
    },
    "id": "54e6ffdc-3c5e-468f-9ed7-f703cb9ddad8",
    "outputId": "6883936f-1343-4b7b-f336-4bc0ef7bd236"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_690/3731126626.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embed = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
      "/usr/local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2025-04-24 12:19:29.034600: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-24 12:19:29.088113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-24 12:19:31.397546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-24 12:19:31.405048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-04-24 12:19:31.406927: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOC-NOTICE: GPU memory for this assignment is capped at 2048MiB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced3c9e66b954825b02b923b103f8684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1628d57d2eb7453aa2110ce435df3957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2090a2f9542147e0a63067657b4a91ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45c17bd7c6f413ea36a56b439cbe9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ed424789d045e5b9c504344c142593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12cddda452b148b5bc6b8257da1c49ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e22f7b05c6a41fd89e7903f1eb42a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f790f75f804cac964d86fd83ac394c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb50f86707ee4330a0daf593f897854d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f052475f3bb94d7ab173a856f699ae70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bc568dd3a640faa8da3350bb9ad205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "hf_embed = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "text = split_texts[0].page_content\n",
    "hf_embed_result = hf_embed.embed_documents([text])\n",
    "print(len(hf_embed_result[0]))  # Prints the length of the first embedded document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3x-PVKuQO6sh",
   "metadata": {
    "id": "3x-PVKuQO6sh"
   },
   "source": [
    "# **Step 6: Embed the Documents Using OpenAIEmbeddings and Print the Length of the Embedding**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff51eb44-7891-4625-b69a-2071ed81fdef",
   "metadata": {
    "id": "ff51eb44-7891-4625-b69a-2071ed81fdef",
    "outputId": "fa0fa7a4-a1e4-45b0-d4d8-cb911e191dfa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_690/2955926699.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  openai_embed = OpenAIEmbeddings()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "openai_embed = OpenAIEmbeddings()\n",
    "openai_embed_result = openai_embed.embed_documents([text])\n",
    "print(len(openai_embed_result[0]))  # Prints the length of the first embedded document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MEtwmKkJPII8",
   "metadata": {
    "id": "MEtwmKkJPII8"
   },
   "source": [
    "# **Step 7: Create a FAISS Instance**\n",
    "\n",
    "*   Create a FAISS instance using the split texts and the OpenAIEmbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f90478cb-1356-4a0d-8250-e055c9dcf511",
   "metadata": {
    "id": "f90478cb-1356-4a0d-8250-e055c9dcf511"
   },
   "outputs": [],
   "source": [
    "# Create FAISS instance from documents and embeddings\n",
    "faiss_index = FAISS.from_documents(split_texts, openai_embed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XTWZ3kgJPT5J",
   "metadata": {
    "id": "XTWZ3kgJPT5J"
   },
   "source": [
    "# **Step 8: Perform a Similarity Search on the FAISS Instance**\n",
    "\n",
    "\n",
    "*   Print the top two most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f78e000-488a-47e2-9b0d-9bfa215703b8",
   "metadata": {
    "id": "5f78e000-488a-47e2-9b0d-9bfa215703b8",
    "outputId": "6da6683d-f734-4d61-9a23-7c50a507a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='dbc62b0f-22cd-4283-a0a7-9b3fbf32dbbe', metadata={'producer': 'BCL easyPDF 2.00.030', 'creator': 'PyPDF', 'creationdate': '', 'source': 'michael_resume.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='spring 2005, I went fully digital, and all photographs can be supplied in electronic format. \\n \\nComputer knowledge  \\nI am reasonably fluent in basic PC computer skills, using Windows XP, Word, WordPro, Excel, PowerPoint, \\nAdobe Photoshop Elements, e-mail, internet etc.  I have full computer and broadband facilities at home. \\n \\nOther interests  \\nBotanising (especially mountain flowers), travel, walking, Scottish islands, gardening, photography, \\ncomputers, rugby supporter, cinema, good wine, Runrig concerts (!). \\n \\n[updated, 26.03.08]'), 0.45549238), (Document(id='50bccc31-eaba-499d-96fc-67f89efbeecc', metadata={'producer': 'BCL easyPDF 2.00.030', 'creator': 'PyPDF', 'creationdate': '', 'source': 'michael_resume.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='CURRICULUM VITAE :  \\nM ichael M . Scott OBE, B.Sc., Dip.Ed  \\n \\nHome address :  Strome House     Date of Birth : 10.5.51 \\n   North Strome     Place of Birth : Edinburgh \\n   Lochcarron     Married to Sue Scott; 2 stepchildren \\n   Ross-shire, IV54 8YJ \\nTelephone (work) : 01520 722901     Website : www.mmscott.co.uk  \\nTelephone (home) :  01520 722588    E-mail :  MSStrome@aol.com  \\n \\nAwarded OBE in Queen’s Birthday Honours, June 2005, “for services to biodiversity conservation in \\nScotland”. \\nAwarded Planta Europa ‘Silver Lead’ Award in September 2007, “for excellent work in European wild plant \\nconservation”. \\n \\nEducation  \\nPrimary education: George Heriots School, Edinburgh (1956-1962) \\nSecondary education:  Madras College, St Andrews (1962-69). \\nFurther education: University of Aberdeen (1969-1974): \\n    Bachelor of Science (Honours; upper second) in Botany, 1973 \\n    Diploma of Education, 1974 \\n   Aberdeen College of Education (1973 - 1974):'), 0.48408833)]\n"
     ]
    }
   ],
   "source": [
    "# Perform a similarity search and print the top two most similar documents\n",
    "search_result = faiss_index.similarity_search_with_score(\"What is the candidate's skill sets?\", k=2)\n",
    "print(search_result)  # Prints the top 2 most similar documents to the query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "J1ffr9-DPeTG",
   "metadata": {
    "id": "J1ffr9-DPeTG"
   },
   "source": [
    "# **Step 9: Persist the FAISS Instance**\n",
    "\n",
    "\n",
    "*   Create a folder in the current working directory that persists the FAISS instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c1584d4-a90f-45f6-b013-af11b3882ccb",
   "metadata": {
    "id": "1c1584d4-a90f-45f6-b013-af11b3882ccb"
   },
   "outputs": [],
   "source": [
    "# Save the FAISS index to a file\n",
    "faiss_index.save_local(\"faiss_index\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OUDWU3cAPx5a",
   "metadata": {
    "id": "OUDWU3cAPx5a"
   },
   "source": [
    "# **Step 10: Load the Persisted FAISS Instance**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb19c4c-122f-44f0-ad74-10d32a2c882c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(id='dbc62b0f-22cd-4283-a0a7-9b3fbf32dbbe', metadata={'producer': 'BCL easyPDF 2.00.030', 'creator': 'PyPDF', 'creationdate': '', 'source': 'michael_resume.pdf', 'total_pages': 4, 'page': 3, 'page_label': '4'}, page_content='spring 2005, I went fully digital, and all photographs can be supplied in electronic format. \\n \\nComputer knowledge  \\nI am reasonably fluent in basic PC computer skills, using Windows XP, Word, WordPro, Excel, PowerPoint, \\nAdobe Photoshop Elements, e-mail, internet etc.  I have full computer and broadband facilities at home. \\n \\nOther interests  \\nBotanising (especially mountain flowers), travel, walking, Scottish islands, gardening, photography, \\ncomputers, rugby supporter, cinema, good wine, Runrig concerts (!). \\n \\n[updated, 26.03.08]'), 0.45549238), (Document(id='50bccc31-eaba-499d-96fc-67f89efbeecc', metadata={'producer': 'BCL easyPDF 2.00.030', 'creator': 'PyPDF', 'creationdate': '', 'source': 'michael_resume.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}, page_content='CURRICULUM VITAE :  \\nM ichael M . Scott OBE, B.Sc., Dip.Ed  \\n \\nHome address :  Strome House     Date of Birth : 10.5.51 \\n   North Strome     Place of Birth : Edinburgh \\n   Lochcarron     Married to Sue Scott; 2 stepchildren \\n   Ross-shire, IV54 8YJ \\nTelephone (work) : 01520 722901     Website : www.mmscott.co.uk  \\nTelephone (home) :  01520 722588    E-mail :  MSStrome@aol.com  \\n \\nAwarded OBE in Queen’s Birthday Honours, June 2005, “for services to biodiversity conservation in \\nScotland”. \\nAwarded Planta Europa ‘Silver Lead’ Award in September 2007, “for excellent work in European wild plant \\nconservation”. \\n \\nEducation  \\nPrimary education: George Heriots School, Edinburgh (1956-1962) \\nSecondary education:  Madras College, St Andrews (1962-69). \\nFurther education: University of Aberdeen (1969-1974): \\n    Bachelor of Science (Honours; upper second) in Botany, 1973 \\n    Diploma of Education, 1974 \\n   Aberdeen College of Education (1973 - 1974):'), 0.48408833)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Load the persisted FAISS index from the file with deserialization allowed\n",
    "faiss_index_loaded = FAISS.load_local(\n",
    "    \"faiss_index\", \n",
    "    openai_embed, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# Perform a similarity search with the loaded FAISS index\n",
    "vector_search_result = faiss_index_loaded.similarity_search_with_score(\n",
    "    \"What is the candidate's skill sets?\", k=2\n",
    ")\n",
    "print(vector_search_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RqaeWpZkQCRc",
   "metadata": {
    "id": "RqaeWpZkQCRc"
   },
   "source": [
    "# **Conclusion**\n",
    "\n",
    "This activity provided a step-by-step guide on how to use LangChain’s loaders, splitters, embeddings, and vector stores. You now know how to load documents, split them into manageable chunks, embed them into a numerical space, and store these embeddings for efficient similarity searches."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
